{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e90bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from simple_contrastive_loss import contrastive_loss\n",
    "from generate_simCLR_pairs import generate_pairs_simCLR\n",
    "from buildSiameseModel import buildModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5139eb63",
   "metadata": {},
   "source": [
    "# Build Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f47222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## Load weights for ResNet50 & add classifier head ##\n",
    "#####################################################\n",
    "def build_base_model():\n",
    "    conv_base = tf.keras.models.load_model(\"~/scratch/gpfs/eysu/SoftCL/models/ResNet50_weights\")\n",
    "\n",
    "    # add classifier on top of conv_base\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # upsample to resize inputs of CIFAR10 from (32x32x3) to (256x256x3)\n",
    "    model.add(layers.UpSampling2D(size=(2,2)))\n",
    "    model.add(layers.UpSampling2D(size=(2,2)))\n",
    "    model.add(layers.UpSampling2D(size=(2,2)))\n",
    "    model.add(conv_base)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizers.RMSprop(learning_rate=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01289a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "def build_siamese_model(inputShape, embeddingDim=48):\n",
    "    # specify the inputs for the feature extractor network\n",
    "    inputs = Input(inputShape)\n",
    "    # define the first set of CONV => RELU => POOL => DROPOUT layers\n",
    "    x = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    # second set of CONV => RELU => POOL => DROPOUT layers\n",
    "    x = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # prepare the final outputs\n",
    "    pooledOutput = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(embeddingDim)(pooledOutput)\n",
    "    # build the model\n",
    "    model = Model(inputs, outputs)\n",
    "    # return the model to the calling function\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0199eda",
   "metadata": {},
   "source": [
    "# Load CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c6c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Load, partition, and resize CIFAR10 Data ##\n",
    "##############################################\n",
    "def loadData():\n",
    "    import pickle\n",
    "\n",
    "    # unpickle the binary files\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "\n",
    "    labels = ['airplane',  # index 0\n",
    "          'automobile',  # index 1\n",
    "          'bird',  # index 2 \n",
    "          'cat',  # index 3 \n",
    "          'deer',  # index 4\n",
    "          'dog',  # index 5\n",
    "          'frog',  # index 6 \n",
    "          'horse',  # index 7 \n",
    "          'ship',  # index 8 \n",
    "          'truck']  # index 9\n",
    "    \n",
    "    # paths to each batch of data\n",
    "    batch1 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_1\")\n",
    "    batch2 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_2\")\n",
    "    batch3 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_3\")\n",
    "    batch4 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_4\")\n",
    "    batch5 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_5\")\n",
    "    meta = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/batches.meta\")\n",
    "    test = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/test_batch\")\n",
    "\n",
    "    # separate labels and image data from each batch\n",
    "    y_train1 = batch1[b'labels']\n",
    "    x_train1 = batch1[b'data']\n",
    "    y_train2 = batch2[b'labels']\n",
    "    x_train2 = batch2[b'data']\n",
    "    y_train3 = batch3[b'labels']\n",
    "    x_train3 = batch3[b'data']\n",
    "    y_train4 = batch4[b'labels']\n",
    "    x_train4 = batch4[b'data']\n",
    "    y_train5 = batch5[b'labels']\n",
    "    x_train5 = batch5[b'data']\n",
    "\n",
    "    # concatenate into big training and testing arrays\n",
    "    y_train = np.concatenate((y_train1, y_train2, y_train3, y_train4, y_train5))\n",
    "    x_train = np.concatenate((x_train1, x_train2, x_train3, x_train4, x_train5), axis=0)\n",
    "    \n",
    "    y_test = test[b'labels']\n",
    "    x_test = test[b'data']\n",
    "    \n",
    "    # Further break training data into train / validation sets \n",
    "    # put 5000 into validation set and keep remaining 45,000 for train\n",
    "    (x_train, x_valid) = x_train[1000:], x_train[:1000] \n",
    "    (y_train, y_valid) = y_train[1000:], y_train[:1000]\n",
    "\n",
    "    # reshape data to match dimensions of cifar10.load_data\n",
    "    x_train = x_train.reshape(49000, 3, 32, 32)\n",
    "    x_train = x_train.transpose(0, 2, 3, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_train /= 255\n",
    "\n",
    "    x_valid = x_valid.reshape(1000, 3, 32, 32)\n",
    "    x_valid = x_valid.transpose(0, 2, 3, 1)\n",
    "    x_valid = x_valid.astype('float32')\n",
    "    x_valid /= 255\n",
    "\n",
    "    x_test = x_test.reshape(10000, 3, 32, 32)\n",
    "    x_test = x_test.transpose(0, 2, 3, 1)\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    y_valid = np.array(y_valid)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    \n",
    "    # preprocess data to convert from RGB -> BGR and to zero center around ImageNet dataset\n",
    "    x_train = tf.keras.applications.resnet50.preprocess_input(x_train)\n",
    "    x_valid = tf.keras.applications.resnet50.preprocess_input(x_valid)\n",
    "    x_test = tf.keras.applications.resnet50.preprocess_input(x_test)\n",
    "    \n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc75cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb41b4",
   "metadata": {},
   "source": [
    "# Fine Tune ResNet50 to CIFAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair_images, train_pair_labels, train_pair_PosNeg = generate_pairs_simCLR(x_test, y_test)\n",
    "valid_pair_images, valid_pair_labels, valid_pair_PosNeg = generate_pairs_simCLR(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36d28def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model():\n",
    "    \n",
    "    train_pair_images, train_pair_labels, train_pair_PosNeg = generate_pairs_simCLR(x_test, y_test)\n",
    "    valid_pair_images, valid_pair_labels, valid_pair_PosNeg = generate_pairs_simCLR(x_valid, y_valid)\n",
    "    \n",
    "    # siamese model configurations\n",
    "    imgsA = layers.Input(shape=(32,32,3))\n",
    "    imgsB = layers.Input(shape=(32,32,3))\n",
    "    \n",
    "    # build two models and train them on each set of images\n",
    "    base_model = build_base_model()\n",
    "    \n",
    "    ####### MAKE IT SUCH THAT TEH BASE MODEL OUTPUTS THE EMBEDDINGS AND NOT THE SOFTMAX ???\n",
    "    \n",
    "    historyA = base_model.fit(train_pair_images[:, 0], train_pair_labels[:, 0], epochs=1, batch_size=64)\n",
    "\n",
    "    # extract the last layer latent space embedding vectors for the training data\n",
    "    # each set of embeddings is of shape bsz x dim (64x128 in our case)\n",
    "    layersA = base_model.layers\n",
    "    embeddingsA, _ = layersA[-4].get_weights()\n",
    "    embeddingsA = embeddingsA.T\n",
    "    \n",
    "    historyB = base_model.fit(train_pair_images[:, 1], train_pair_labels[:, 1], epochs=1, batch_size=64)\n",
    "    layersB = base_model.layers\n",
    "    embeddingsB, _ = layersB[-4].get_weights()\n",
    "    embeddingsB = embeddingsB.T\n",
    "    \n",
    "    # calculate the distance between the embedding vectors\n",
    "    dist = layers.Lambda(euclidean_distance)([embeddingsA, embeddingsB])\n",
    "    \n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(dist).output\n",
    "#     outputs = tf.convert_to_tensor(outputs)\n",
    "    \n",
    "    siamese_model = models.Model(inputs=[imgsA, imgsB], outputs = outputs)\n",
    "    \n",
    "    return outputs, siamese_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30e400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df023332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "625/625 [==============================] - 78s 114ms/step - loss: 0.7753 - accuracy: 0.2962\n",
      "625/625 [==============================] - 72s 115ms/step - loss: 0.6725 - accuracy: 0.5404\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs, siamese_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_siamese_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mbuild_siamese_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# calculate the distance between the embedding vectors\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     dist \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLambda(euclidean_distance)([embeddingsA, embeddingsB])\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msigmoid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#     outputs = tf.convert_to_tensor(outputs)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     siamese_model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[imgsA, imgsB], outputs \u001b[38;5;241m=\u001b[39m outputs)\n",
      "File \u001b[0;32m~/.conda/envs/tf2-gpu/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:513\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    506\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    507\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[1;32m    508\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124m    from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124m    np_config.enable_numpy_behavior()\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[0;32m--> 513\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'output'"
     ]
    }
   ],
   "source": [
    "outputs, siamese_model = build_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9092f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = siamese_model.fit([train_pair_images[:, 0], train_pair_images[:, 1]], \n",
    "    train_pair_PosNeg, \n",
    "    epochs=5, \n",
    "    batch_size=64,\n",
    "    validation_data=([valid_pair_images[:, 0], valid_pair_images[:,1]], valid_pair_PosNeg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b54fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "def euclidean_distance(vectors):\n",
    "    # unpack the vectors into separate lists\n",
    "    (featsA, featsB) = vectors\n",
    "    # compute the sum of squared distances between the vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
    "        keepdims=True)\n",
    "    # return the euclidean distance between the vectors\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0910b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility to display training and validation curves\n",
    "def plot_metrics(metric_name, title):\n",
    "    \n",
    "    plt.plot(history.history[metric_name],color='blue',label='training_' + metric_name)\n",
    "    plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)\n",
    "\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81525cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "model = tf.keras.models.load_model(\"~/scratch/gpfs/eysu/SoftCL/models/ResNet50+CIFAR_2\")\n",
    "\n",
    "history = model.fit(x_test, y_test, epochs=EPOCHS, validation_data = (x_valid, y_valid), batch_size=64)\n",
    "loss, accuracy = model.evaluate(x_valid, y_valid, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\"loss\", \"Loss curve\")\n",
    "plot_metrics(\"accuracy\", \"Accuracy curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e2dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c2a743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc58700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## Load weights for ResNet50 & add classifier head ##\n",
    "#####################################################\n",
    "def build_base_model(sims, bsz):\n",
    "    conv_base = tf.keras.models.load_model(\"~/scratch/gpfs/eysu/SoftCL/models/ResNet50_weights\")\n",
    "    \n",
    "    # add classifier on top of conv_base\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # upsample to resize inputs of CIFAR10 from (32x32x3) to (256x256x3)\n",
    "    model.add(layers.UpSampling2D(size=(2,2)))\n",
    "    model.add(layers.UpSampling2D(size=(2,2)))\n",
    "    model.add(layers.UpSampling2D(size=(2,2)))\n",
    "    model.add(conv_base)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    embed_layer = model.layers[-4]\n",
    "    \n",
    "    loss_params = (sims, embed_layer, bsz)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=contrastive_loss(loss_params), metrics=['accuracy'], run_eagerly=True)\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62cfe1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eysu/.conda/envs/tf2-gpu/lib/python3.10/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/eysu/.conda/envs/tf2-gpu/lib/python3.10/site-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "from simCLR_CIFAR import findSims\n",
    "sims = findSims(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c56cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 03:01:50.983709: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 03:01:51.384096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38370 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 03:01:53.434653: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8401\n",
      "2023-05-09 03:01:54.166033: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-09 03:01:54.387603: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "/home/eysu/.conda/envs/tf2-gpu/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 49s 288ms/step - loss: 1278.5419 - accuracy: 0.1514 - val_loss: 1107.3503 - val_accuracy: 0.0920\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 44s 278ms/step - loss: 1169.3365 - accuracy: 0.1986 - val_loss: 3461.3987 - val_accuracy: 0.0990\n",
      "Epoch 3/10\n",
      " 47/157 [=======>......................] - ETA: 28s - loss: 1128.5645 - accuracy: 0.2553"
     ]
    }
   ],
   "source": [
    "model = build_base_model(sims, 64)\n",
    "\n",
    "history = model.fit(x_test, y_test, epochs=10, batch_size=64, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96808842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu [~/.conda/envs/tf2-gpu/]",
   "language": "python",
   "name": "conda_tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
