{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e90bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from simple_contrastive_loss import contrastive_loss\n",
    "from generate_simCLR_pairs import generate_pairs_simCLR\n",
    "from buildSiameseModel import buildModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5139eb63",
   "metadata": {},
   "source": [
    "# Build Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f47222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## Load weights for ResNet50 & add classifier head ##\n",
    "#####################################################\n",
    "def build_base_model():\n",
    "    conv_base = tf.keras.models.load_model(\"~/scratch/gpfs/eysu/SoftCL/models/ResNet50_weights\")\n",
    "\n",
    "    # add classifier on top of conv_base\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # upsample to resize inputs of CIFAR10 from (32x32x3) to (256x256x3)\n",
    "    model.add(layers.UpSampling2D(size=(2,2)))\n",
    "    model.add(layers.UpSampling2D(size=(2,2)))\n",
    "    model.add(layers.UpSampling2D(size=(2,2)))\n",
    "    model.add(conv_base)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizers.RMSprop(learning_rate=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0199eda",
   "metadata": {},
   "source": [
    "# Load CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Load, partition, and resize CIFAR10 Data ##\n",
    "##############################################\n",
    "def loadData():\n",
    "    import pickle\n",
    "\n",
    "    # unpickle the binary files\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "\n",
    "    labels = ['airplane',  # index 0\n",
    "          'automobile',  # index 1\n",
    "          'bird',  # index 2 \n",
    "          'cat',  # index 3 \n",
    "          'deer',  # index 4\n",
    "          'dog',  # index 5\n",
    "          'frog',  # index 6 \n",
    "          'horse',  # index 7 \n",
    "          'ship',  # index 8 \n",
    "          'truck']  # index 9\n",
    "    \n",
    "    # paths to each batch of data\n",
    "    batch1 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_1\")\n",
    "    batch2 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_2\")\n",
    "    batch3 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_3\")\n",
    "    batch4 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_4\")\n",
    "    batch5 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_5\")\n",
    "    meta = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/batches.meta\")\n",
    "    test = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/test_batch\")\n",
    "\n",
    "    # separate labels and image data from each batch\n",
    "    y_train1 = batch1[b'labels']\n",
    "    x_train1 = batch1[b'data']\n",
    "    y_train2 = batch2[b'labels']\n",
    "    x_train2 = batch2[b'data']\n",
    "    y_train3 = batch3[b'labels']\n",
    "    x_train3 = batch3[b'data']\n",
    "    y_train4 = batch4[b'labels']\n",
    "    x_train4 = batch4[b'data']\n",
    "    y_train5 = batch5[b'labels']\n",
    "    x_train5 = batch5[b'data']\n",
    "\n",
    "    # concatenate into big training and testing arrays\n",
    "    y_train = np.concatenate((y_train1, y_train2, y_train3, y_train4, y_train5))\n",
    "    x_train = np.concatenate((x_train1, x_train2, x_train3, x_train4, x_train5), axis=0)\n",
    "    \n",
    "    y_test = test[b'labels']\n",
    "    x_test = test[b'data']\n",
    "    \n",
    "    # Further break training data into train / validation sets \n",
    "    # put 5000 into validation set and keep remaining 45,000 for train\n",
    "    (x_train, x_valid) = x_train[1000:], x_train[:1000] \n",
    "    (y_train, y_valid) = y_train[1000:], y_train[:1000]\n",
    "\n",
    "    # reshape data to match dimensions of cifar10.load_data\n",
    "    x_train = x_train.reshape(49000, 3, 32, 32)\n",
    "    x_train = x_train.transpose(0, 2, 3, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_train /= 255\n",
    "\n",
    "    x_valid = x_valid.reshape(1000, 3, 32, 32)\n",
    "    x_valid = x_valid.transpose(0, 2, 3, 1)\n",
    "    x_valid = x_valid.astype('float32')\n",
    "    x_valid /= 255\n",
    "\n",
    "    x_test = x_test.reshape(10000, 3, 32, 32)\n",
    "    x_test = x_test.transpose(0, 2, 3, 1)\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    y_valid = np.array(y_valid)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    \n",
    "    # preprocess data to convert from RGB -> BGR and to zero center around ImageNet dataset\n",
    "    x_train = tf.keras.applications.resnet50.preprocess_input(x_train)\n",
    "    x_valid = tf.keras.applications.resnet50.preprocess_input(x_valid)\n",
    "    x_test = tf.keras.applications.resnet50.preprocess_input(x_test)\n",
    "    \n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc75cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb41b4",
   "metadata": {},
   "source": [
    "# Build Siamese Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b54fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "def euclidean_distance(vectors):\n",
    "    # unpack the vectors into separate lists\n",
    "    (featsA, featsB) = vectors\n",
    "    # compute the sum of squared distances between the vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
    "        keepdims=True)\n",
    "    # return the euclidean distance between the vectors\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d28def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model():\n",
    "    \n",
    "    train_pair_images, train_pair_labels, train_pair_PosNeg = generate_pairs_simCLR(x_test, y_test)\n",
    "    valid_pair_images, valid_pair_labels, valid_pair_PosNeg = generate_pairs_simCLR(x_valid, y_valid)\n",
    "    \n",
    "    # siamese model configurations\n",
    "    imgsA = layers.Input(shape=(32,32,3))\n",
    "    imgsB = layers.Input(shape=(32,32,3))\n",
    "    \n",
    "    # build two models and train them on each set of images\n",
    "    base_model = build_base_model()\n",
    "    \n",
    "    ####### MAKE IT SUCH THAT TEH BASE MODEL OUTPUTS THE EMBEDDINGS AND NOT THE SOFTMAX ???\n",
    "    \n",
    "    historyA = base_model.fit(train_pair_images[:, 0], train_pair_labels[:, 0], epochs=1, batch_size=64)\n",
    "\n",
    "    # extract the last layer latent space embedding vectors for the training data\n",
    "    # each set of embeddings is of shape bsz x dim (64x128 in our case)\n",
    "    layersA = base_model.layers\n",
    "    embeddingsA, _ = layersA[-4].get_weights()\n",
    "    embeddingsA = embeddingsA.T\n",
    "    \n",
    "    historyB = base_model.fit(train_pair_images[:, 1], train_pair_labels[:, 1], epochs=1, batch_size=64)\n",
    "    layersB = base_model.layers\n",
    "    embeddingsB, _ = layersB[-4].get_weights()\n",
    "    embeddingsB = embeddingsB.T\n",
    "    \n",
    "    # calculate the distance between the embedding vectors\n",
    "    dist = layers.Lambda(euclidean_distance)([embeddingsA, embeddingsB])\n",
    "    \n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(dist).output\n",
    "#     outputs = tf.convert_to_tensor(outputs)\n",
    "    \n",
    "    siamese_model = models.Model(inputs=[imgsA, imgsB], outputs = outputs)\n",
    "    \n",
    "    return outputs, siamese_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df023332",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, siamese_model = build_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9092f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = siamese_model.fit([train_pair_images[:, 0], train_pair_images[:, 1]], \n",
    "    train_pair_PosNeg, \n",
    "    epochs=5, \n",
    "    batch_size=64,\n",
    "    validation_data=([valid_pair_images[:, 0], valid_pair_images[:,1]], valid_pair_PosNeg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0910b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility to display training and validation curves\n",
    "def plot_metrics(metric_name, title):\n",
    "    \n",
    "    plt.plot(history.history[metric_name],color='blue',label='training_' + metric_name)\n",
    "    plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)\n",
    "\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96808842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu [~/.conda/envs/tf2-gpu/]",
   "language": "python",
   "name": "conda_tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
