{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e90bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5139eb63",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c6cfdc",
   "metadata": {},
   "source": [
    "#### THIS CELL IS NOT RAN #####\n",
    "##### Pre constructed this model and saved weights in \"~/scratch/gpfs/eysu/SoftCL/models/ResNet50+CIFAR\" ####\n",
    "\n",
    "####################################################\n",
    "## Build Model using ResNet50 and Classifier Head ##\n",
    "####################################################\n",
    "\n",
    "'''\n",
    "Feature Extraction is performed by ResNet50 pretrained on imagenet weights. \n",
    "Input size is 224 x 224.\n",
    "'''\n",
    "def feature_extractor(inputs):\n",
    "\n",
    "  feature_extractor = tf.keras.applications.resnet.ResNet50(input_shape=(224, 224, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')(inputs)\n",
    "  return feature_extractor\n",
    "\n",
    "\n",
    "'''\n",
    "Defines final dense layers and subsequent softmax layer for classification.\n",
    "'''\n",
    "def classifier(inputs):\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n",
    "    return x\n",
    "\n",
    "'''\n",
    "Since input image size is (32 x 32), first upsample the image by factor of (7x7) to transform it to (224 x 224)\n",
    "Connect the feature extraction and \"classifier\" layers to build the model.\n",
    "'''\n",
    "def final_model(inputs):\n",
    "\n",
    "    resize = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n",
    "\n",
    "    resnet_feature_extractor = feature_extractor(resize)\n",
    "    classification_output = classifier(resnet_feature_extractor)\n",
    "\n",
    "    return classification_output\n",
    "\n",
    "'''\n",
    "Define the model and compile it. \n",
    "Use Stochastic Gradient Descent as the optimizer.\n",
    "Use Sparse Categorical CrossEntropy as the loss function.\n",
    "'''\n",
    "def define_compile_model():\n",
    "  inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
    "  \n",
    "  classification_output = final_model(inputs) \n",
    "  model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n",
    " \n",
    "  model.compile(optimizer='SGD', \n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "model = define_compile_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f47222",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "## Load saved model ##\n",
    "######################\n",
    "\n",
    "model = tf.keras.models.load_model(\"~/scratch/gpfs/eysu/SoftCL/models/ResNet50+CIFAR_2\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0199eda",
   "metadata": {},
   "source": [
    "# Load CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Load, partition, and resize CIFAR10 Data ##\n",
    "##############################################\n",
    "def loadData():\n",
    "    import pickle\n",
    "\n",
    "    # unpickle the binary files\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "\n",
    "    labels = ['airplane',  # index 0\n",
    "          'automobile',  # index 1\n",
    "          'bird',  # index 2 \n",
    "          'cat',  # index 3 \n",
    "          'deer',  # index 4\n",
    "          'dog',  # index 5\n",
    "          'frog',  # index 6 \n",
    "          'horse',  # index 7 \n",
    "          'ship',  # index 8 \n",
    "          'truck']  # index 9\n",
    "    \n",
    "    # paths to each batch of data\n",
    "    batch1 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_1\")\n",
    "    batch2 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_2\")\n",
    "    batch3 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_3\")\n",
    "    batch4 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_4\")\n",
    "    batch5 = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/data_batch_5\")\n",
    "    meta = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/batches.meta\")\n",
    "    test = unpickle(\"/scratch/gpfs/eysu/src_data/cifar-10-batches-py/test_batch\")\n",
    "\n",
    "    # separate labels and image data from each batch\n",
    "    y_train1 = batch1[b'labels']\n",
    "    x_train1 = batch1[b'data']\n",
    "    y_train2 = batch2[b'labels']\n",
    "    x_train2 = batch2[b'data']\n",
    "    y_train3 = batch3[b'labels']\n",
    "    x_train3 = batch3[b'data']\n",
    "    y_train4 = batch4[b'labels']\n",
    "    x_train4 = batch4[b'data']\n",
    "    y_train5 = batch5[b'labels']\n",
    "    x_train5 = batch5[b'data']\n",
    "\n",
    "    # concatenate into big training and testing arrays\n",
    "    y_train = np.concatenate((y_train1, y_train2, y_train3, y_train4, y_train5))\n",
    "    x_train = np.concatenate((x_train1, x_train2, x_train3, x_train4, x_train5), axis=0)\n",
    "    \n",
    "    y_test = test[b'labels']\n",
    "    x_test = test[b'data']\n",
    "    \n",
    "    # Further break training data into train / validation sets \n",
    "    # put 5000 into validation set and keep remaining 45,000 for train\n",
    "    (x_train, x_valid) = x_train[1000:], x_train[:1000] \n",
    "    (y_train, y_valid) = y_train[1000:], y_train[:1000]\n",
    "\n",
    "    # reshape data to match dimensions of cifar10.load_data\n",
    "    x_train = x_train.reshape(49000, 3, 32, 32)\n",
    "    x_train = x_train.transpose(0, 2, 3, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_train /= 255\n",
    "\n",
    "    x_valid = x_valid.reshape(1000, 3, 32, 32)\n",
    "    x_valid = x_valid.transpose(0, 2, 3, 1)\n",
    "    x_valid = x_valid.astype('float32')\n",
    "    x_valid /= 255\n",
    "\n",
    "    x_test = x_test.reshape(10000, 3, 32, 32)\n",
    "    x_test = x_test.transpose(0, 2, 3, 1)\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_test /= 255\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    y_valid = np.array(y_valid)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    \n",
    "    # preprocess data to convert from RGB -> BGR and to zero center around ImageNet dataset\n",
    "    x_train = tf.keras.applications.resnet50.preprocess_input(x_train)\n",
    "    x_valid = tf.keras.applications.resnet50.preprocess_input(x_valid)\n",
    "    x_test = tf.keras.applications.resnet50.preprocess_input(x_test)\n",
    "    \n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc75cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test, labels = loadData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb41b4",
   "metadata": {},
   "source": [
    "# Fine Tune ResNet50 to CIFAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0910b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility to display training and validation curves\n",
    "def plot_metrics(metric_name, title):\n",
    "    \n",
    "    plt.plot(history.history[metric_name],color='blue',label='training_' + metric_name)\n",
    "    plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)\n",
    "\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81525cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "model = tf.keras.models.load_model(\"~/scratch/gpfs/eysu/SoftCL/models/ResNet50+CIFAR_2\")\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=EPOCHS, validation_data = (x_valid, y_valid), batch_size=64)\n",
    "loss, accuracy = model.evaluate(x_valid, y_valid, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\"loss\", \"Loss curve\")\n",
    "plot_metrics(\"accuracy\", \"Accuracy curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e2dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu [~/.conda/envs/tf2-gpu/]",
   "language": "python",
   "name": "conda_tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
